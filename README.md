# Chain of Attack: On the Robustness of Vision-Language Models Against Transfer-Based Adversarial Attacks

We present Chain of Attack (CoA), which iteratively enhances the generation of adversarial examples based on the multi-modal semantic update using a series of intermediate attacking steps, achieving superior adversarial transferability and efficiency. A unified attack success rate computing method is further proposed for automatic evasion evaluation. Extensive experiments conducted under the mostrealistic and high-stakes scenario, demonstrate that our attacking strategy can effectively mislead models to generate targeted responses using only black-box attacks without any knowledge of the victim models. The comprehensive robustness evaluation in our paper provides insight into the vulnerabilities of VLMs and offers a reference for the safety considerations of future model developments. [[Paper](https://arxiv.org/pdf/2411.15720)]


## ğŸš€ News
- [28/02/2025] Chain of Attack is accepted by CVPR 2025!
- [24/11/2024] The manuscript can be found on [arXiv](https://arxiv.org/pdf/2411.15720).

  
## ğŸ“šCitation

```bibtex
@article{xie2024chain,
  title={Chain of Attack: On the Robustness of Vision-Language Models Against Transfer-Based Adversarial Attacks},
  author={Xie, Peng and Bie, Yequan and Mao, Jianda and Song, Yangqiu and Wang, Yang and Chen, Hao and Chen, Kani},
  journal={arXiv preprint arXiv:2411.15720},
  year={2024}
}
```

## ğŸ“„License

## ğŸ™Acknowledgement
